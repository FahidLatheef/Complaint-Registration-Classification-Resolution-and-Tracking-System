{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########################################################################\n",
    "## Consumer complaints classification model\n",
    "### Author : Fahid Latheef A\n",
    "### Date written: 21-Oct-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########################################################################\n",
    "### Aim: To assign the complaints to most appropriate department\n",
    "### Dataset for training: complaints.csv\n",
    "### Description: \n",
    "##### This module builds machine learning model that can classify consumer complaints to different catogories\n",
    "##### The model is saved in a serializable object using pickle\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input: complaints.csv\n",
    "##### Outputs:\n",
    "###### CC_model_MNB.pkl\n",
    "###### CC_model_LR.pkl\n",
    "###### CC_model_RF.pkl\n",
    "###### CC_model_BLSVC.pkl\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import machine learning model libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'nan']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fahid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# List of stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop.append('nan') # adding nan as a stopword\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load the dataset\n",
    "cc = pd.read_csv('complaints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903983, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the data\n",
    "cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/12/2014</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referral</td>\n",
       "      <td>3/17/2014</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>759217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/1/2016</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Incorrect information on credit report</td>\n",
       "      <td>Account status</td>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>Web</td>\n",
       "      <td>10/5/2016</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2141773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/17/2016</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Vehicle loan</td>\n",
       "      <td>Managing the loan or lease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>10/20/2016</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2163100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/8/2014</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bankruptcy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>6/10/2014</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>885638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/13/2014</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Communication tactics</td>\n",
       "      <td>Frequent or repeated calls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>9/13/2014</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1027760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received           Product     Sub-product  \\\n",
       "0     3/12/2014          Mortgage  Other mortgage   \n",
       "1     10/1/2016  Credit reporting             NaN   \n",
       "2    10/17/2016     Consumer Loan    Vehicle loan   \n",
       "3      6/8/2014       Credit card             NaN   \n",
       "4     9/13/2014   Debt collection     Credit card   \n",
       "\n",
       "                                      Issue                   Sub-issue  \\\n",
       "0  Loan modification,collection,foreclosure                         NaN   \n",
       "1    Incorrect information on credit report              Account status   \n",
       "2                Managing the loan or lease                         NaN   \n",
       "3                                Bankruptcy                         NaN   \n",
       "4                     Communication tactics  Frequent or repeated calls   \n",
       "\n",
       "                        Consumer complaint narrative  \\\n",
       "0                                                NaN   \n",
       "1  I have outdated information on my credit repor...   \n",
       "2  I purchased a new car on XXXX XXXX. The car de...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                             Company public response Submitted via  \\\n",
       "0                                                NaN      Referral   \n",
       "1  Company has responded to the consumer and the ...           Web   \n",
       "2                                                NaN           Web   \n",
       "3                                                NaN           Web   \n",
       "4                                                NaN           Web   \n",
       "\n",
       "  Date sent to company Company response to consumer Timely response?  \\\n",
       "0            3/17/2014      Closed with explanation              Yes   \n",
       "1            10/5/2016      Closed with explanation              Yes   \n",
       "2           10/20/2016      Closed with explanation              Yes   \n",
       "3            6/10/2014      Closed with explanation              Yes   \n",
       "4            9/13/2014      Closed with explanation              Yes   \n",
       "\n",
       "  Consumer disputed?  Complaint ID  \n",
       "0                 No        759217  \n",
       "1                 No       2141773  \n",
       "2                 No       2163100  \n",
       "3                Yes        885638  \n",
       "4                Yes       1027760  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# snapshot of data\n",
    "cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date received                        0\n",
       "Product                              0\n",
       "Sub-product                     235160\n",
       "Issue                                0\n",
       "Sub-issue                       477597\n",
       "Consumer complaint narrative    704013\n",
       "Company public response         646002\n",
       "Submitted via                        0\n",
       "Date sent to company                 0\n",
       "Company response to consumer         0\n",
       "Timely response?                     0\n",
       "Consumer disputed?              135408\n",
       "Complaint ID                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "cc.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     Loan modification,collection,foreclosure nan nan\n",
       "1    Incorrect information on credit report Account...\n",
       "2    Managing the loan or lease nan I purchased a n...\n",
       "3                                   Bankruptcy nan nan\n",
       "4    Communication tactics Frequent or repeated cal...\n",
       "Name: new_complaint_narrative, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# combine 3 columns and apply string function to make one single columns\n",
    "cc['new_complaint_narrative'] = cc[['Issue','Sub-issue','Consumer complaint narrative']].apply(lambda x:\n",
    "                                                                                               ' '.join(x.astype(str)),axis=1)\n",
    "cc['new_complaint_narrative'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     loan modification,collection,foreclosure nan nan\n",
       "1    incorrect information on credit report account...\n",
       "2    managing the loan or lease nan i purchased a n...\n",
       "3                                   bankruptcy nan nan\n",
       "4    communication tactics frequent or repeated cal...\n",
       "Name: new_complaint_narrative, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Converting to lower-case and stripping the whitespaces\n",
    "cc['new_complaint_narrative'] = cc['new_complaint_narrative'].apply(lambda x: x.strip().lower())\n",
    "cc['new_complaint_narrative'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0             loan modification,collection,foreclosure\n",
       "1    incorrect information credit report account st...\n",
       "2    managing loan lease purchased new car xxxx xxx...\n",
       "3                                           bankruptcy\n",
       "4        communication tactics frequent repeated calls\n",
       "Name: new_complaint_narrative, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Remove Stop-Words\n",
    "# stop is the list of stopwords\n",
    "cc['new_complaint_narrative'] = cc['new_complaint_narrative'].apply(lambda words: ' '.join(word.lower()\n",
    "                                                                                           for word in words.split() if word not in stop))\n",
    "cc['new_complaint_narrative'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove punctuations\n",
    "# Replace Punctuations with ' '\n",
    "punctuations = [',', '.', ';', ':', '(', ')', '{', '}', '[', ']']\n",
    "def remove_punctuations(text, punctuations = punctuations):\n",
    "    for letter in text:\n",
    "        if letter in punctuations:\n",
    "            text = text.replace(letter, ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0             loan modification collection foreclosure\n",
       "1    incorrect information credit report account st...\n",
       "2    managing loan lease purchased new car xxxx xxx...\n",
       "3                                           bankruptcy\n",
       "4        communication tactics frequent repeated calls\n",
       "Name: new_complaint_narrative, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Remove Punctuations\n",
    "cc['new_complaint_narrative'] = cc['new_complaint_narrative'].apply(remove_punctuations)\n",
    "cc['new_complaint_narrative'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the required two columns\n",
    "df = cc[['Product','new_complaint_narrative']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903983, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product                    0\n",
       "new_complaint_narrative    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mortgage                                                                        242194\n",
       "Debt collection                                                                 171567\n",
       "Credit reporting                                                                140424\n",
       "Credit card                                                                      89190\n",
       "Bank account or service                                                          86207\n",
       "Credit reporting, credit repair services, or other personal consumer reports     59186\n",
       "Student loan                                                                     38612\n",
       "Consumer Loan                                                                    31608\n",
       "Credit card or prepaid card                                                      11921\n",
       "Checking or savings account                                                       9947\n",
       "Payday loan                                                                       5546\n",
       "Money transfers                                                                   5354\n",
       "Prepaid card                                                                      3819\n",
       "Vehicle loan or lease                                                             2873\n",
       "Payday loan, title loan, or personal loan                                         2245\n",
       "Money transfer, virtual currency, or money service                                2213\n",
       "Other financial service                                                           1059\n",
       "Virtual currency                                                                    18\n",
       "Name: Product, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the different catogories?\n",
    "df.Product.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 604 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# combining product categories\n",
    "df.Product[df.Product == 'Money transfer, virtual currency, or money service'] = 'Money transfers'\n",
    "df.Product[df.Product == 'Prepaid card'] = 'Credit card or prepaid card'\n",
    "df.Product[df.Product == 'Virtual currency'] = 'Money transfers'\n",
    "df.Product[df.Product == 'Payday loan'] = 'Payday loan, title loan, or personal loan'\n",
    "df.Product[df.Product == 'Credit card'] = 'Credit card or prepaid card'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mortgage                                                                        242194\n",
       "Debt collection                                                                 171567\n",
       "Credit reporting                                                                140424\n",
       "Credit card or prepaid card                                                     104930\n",
       "Bank account or service                                                          86207\n",
       "Credit reporting, credit repair services, or other personal consumer reports     59186\n",
       "Student loan                                                                     38612\n",
       "Consumer Loan                                                                    31608\n",
       "Checking or savings account                                                       9947\n",
       "Payday loan, title loan, or personal loan                                         7791\n",
       "Money transfers                                                                   7585\n",
       "Vehicle loan or lease                                                             2873\n",
       "Other financial service                                                           1059\n",
       "Name: Product, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Product.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build ML model pipeline Multinomial NB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "comp_class_MNB = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['new_complaint_narrative'], df['Product'], random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train the model\n",
    "comp_class_MNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9139939261372269"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# accuracy on train data\n",
    "comp_class_MNB.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9124497778721747"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# accuracy on test data\n",
    "comp_class_MNB.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Debt collection']\n"
     ]
    }
   ],
   "source": [
    "new_complaint = [\"This company refuses to provide me verification and validation of debt per my right under the FDCPA. I do not believe this debt is mine.\"]\n",
    "print(comp_class_MNB.predict(new_complaint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 499 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save the model for later use\n",
    "import pickle\n",
    "pickle.dump(comp_class_MNB, open(\"CC_model_MNB.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build ML model pipeline Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "comp_class_LogReg = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression(multi_class='multinomial')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='multinomial', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train the model\n",
    "comp_class_LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9740231007379198"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# accuracy on train data\n",
    "comp_class_LogReg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9714950707092161"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# accuracy on test data\n",
    "comp_class_LogReg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Debt collection']\n"
     ]
    }
   ],
   "source": [
    "new_complaint = [\"This company refuses to provide me verification and validation of debt per my right under the FDCPA. I do not believe this debt is mine.\"]\n",
    "print(comp_class_LogReg.predict(new_complaint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 363 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save the model for later use\n",
    "pickle.dump(comp_class_LogReg, open(\"CC_model_LR.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omitting Decision Tree because Random Forest is a collection of Decision Trees and is better for large Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build ML model pipeline Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "comp_class_RF = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train the model\n",
    "comp_class_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9879599461346604"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# accuracy on Train Data\n",
    "comp_class_RF.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9728269526894281"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# accuracy on test data\n",
    "comp_class_RF.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Debt collection']\n"
     ]
    }
   ],
   "source": [
    "print(comp_class_RF.predict(new_complaint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model for later use\n",
    "pickle.dump(comp_class_RF, open(\"CC_model_RF.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am using BSVC since SVC is taking a lot of time to converge\n",
    "### KNN is very computationally expensive for large dataset, so convergance is slow. ignoring them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "YEvq1Ak74RbP"
   },
   "outputs": [],
   "source": [
    "# build ML model pipeline Bagging Linear Support Vector Classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "comp_class_BLSVC = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BaggingClassifier(LinearSVC(verbose = 1),bootstrap = False)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "2LjJdzYs4RbR",
    "outputId": "28b9c62f-e162-4535-a21e-68cdb5abcb7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Wall time: 9min 23s\n",
      "Parser   : 181 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                                                            class_weight=None,\n",
       "                                                            dual=True,\n",
       "                                                            fit_intercept=True,\n",
       "                                                            intercept_scaling=1,\n",
       "                                                            loss='squared_hinge',\n",
       "                                                            max_iter=1000,\n",
       "                                                            multi_class='ovr',\n",
       "                                                            penalty='l2',\n",
       "                                                            random_state=None,\n",
       "                                                            tol=0.0001,\n",
       "                                                            verbose=1),\n",
       "                                   bootstrap=False, bootstrap_features=False,\n",
       "                                   max_features=1.0, max_samples=1.0,\n",
       "                                   n_estimators=10, n_jobs=None,\n",
       "                                   oob_score=False, random_state=None,\n",
       "                                   verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train the model\n",
    "comp_class_BLSVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "Ajq4NgwU4RbU",
    "outputId": "898c1a81-c863-47ac-b2fa-0b13788ce2e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9813152759566186"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# accuracy on train data\n",
    "comp_class_BLSVC.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "g94sD2HZ4Rba",
    "outputId": "7df20854-bff1-4bb5-80f0-c3e982f27066"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973999539814864"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy on test data\n",
    "comp_class_BLSVC.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "VzVjpebW4Rbf",
    "outputId": "49410997-da7f-487f-9bfa-4eedf4dc2c04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Debt collection']\n"
     ]
    }
   ],
   "source": [
    "print(comp_class_BLSVC.predict([\"This company refuses to provide me verification and validation of debt per my right under the FDCPA. I do not believe this debt is mine.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "KCxK5PTw4Rbj"
   },
   "outputs": [],
   "source": [
    "# save the model for later use\n",
    "pickle.dump(comp_class_BLSVC, open(\"CC_model_BLSVC.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###################################################################################\n",
    "Model ## Training Accuracy ## Testing Accuracy ## Training Time ## Pickle File Size\n",
    "###################################################################################\n",
    "MNB   ## 91.3994%          ## 91.2450%         ##     36s       ## 20.20 MB\n",
    "LR    ## 97.4023%          ## 97.1495%         ##  3m 20s       ## 12.40 MB\n",
    "RF    ## 98.7960%          ## 97.2827%         ## 45m 56s       ##  1.34 GB\n",
    "BLSVC ## 98.1315%          ## 97.3999%         ##  9m 23s       ## 85.60 MB\n",
    "###################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
